### High correlation between gamma and report which is what the problem I had with this model at the
### very beginning. Given the level that we observe (inf_obs), we can produce a given level of I by
### having a higher recovery rate matched by a higher rate of observation

---
title: "NIMBLE + Wrapup"
author: "Mike Li, Morgan Kain"
date:  "`r format(Sys.time(), '%H:%M %d %B %Y')`"
output: html_document
---

Our goals for the final presentation are the following: <br />
1. Describe the use of a powerful tool for MCMC and other applications (Particle Filtering, EM) <br />
2. Present the steps of a validation process using a variety of methods/platforms <br />
3. We do not have much new "Thursday Material" so the majority of our time will be spent in R <br />

## NIMBLE: Numerical Inference for statistical Models for Bayesian and Likelihood Estimation

NIMBLE is built in R but compiles your models and algorithms using C++ for speed <br />
NIMBLE is most commonly used for MCMC but can also be used to implement particle filtering and EM
1. A system for writing statistical models flexibly, which is an extension of the BUGS language <br />
2. A library of algorithms such as MCMC. <br />
3. A language, called NIMBLE, embedded within and similar in style to R, for writing <br />
  algorithms that operate on BUGS models.
  <br />
  
One of the most important concepts behind NIMBLE is to allow a combination of highlevel 
processing in R and low-level processing in compiled C++. <br />

1. NIMBLE extracts all the declarations in the BUGS code to create a model definition. <br />
2. From the model definition, NIMBLE builds a working model in R. This can be used
to manipulate variables and operate the model from R. Operating the model includes
calculating, simulating, or querying the log probability value of model nodes. <br />
3. From the working model, NIMBLE generates customized C++ code representing the
model, compiles the C++, loads it back into R, and provides an R object that interfaces
to it. We often call the uncompiled model the “R-model” and the compiled model the
“C-model.” <br />  

##### Why NIMBLE?

1. Options (More customizable MCMC, ability to run JAGS models and STAN models, EM, particle filter) <br />
2. User-defined functions and distributions – written as nimbleFunctions – can be used
in model code.  <br />
3. Multiple parameterizations for distributions, similar to those in R, can be used. <br />
4. Named parameters for distributions and functions, similar to R function calls, can be
used. <br />
5. More flexible indexing of vector nodes within larger variables is allowed. For example
one can place a multivariate normal vector arbitrarily within a higher-dimensional
object, not just in the last index. <br />
6. More general constraints can be declared using dconstraint, which extends the concept
of JAGS’ dinterval. <br />


#### Downloading, installing and loading NIMBLE

On Windows, you should download and install Rtools.exe available from http://cran. r-project.org/bin/windows/Rtools/.
On OS X, you should install Xcode.
You wil also need the make utility

After these are installed you can install NIMBLE in R using <br />
install.packages("nimble", repos = "http://r-nimble.org", type = "source") <br />

Please post about installation problems to the nimble-users Google group or email nimble.stats@gmail.com.

You will also need to download STAN using the following commands <br />
Sys.setenv(MAKEFLAGS = "-j4") <br />
install.packages("rstan", dependencies = TRUE) <br />

In total you will need the following pakages:

```{r loadpackage, echo=TRUE, message=FALSE}
library("nimble")
library("R2jags")
library("ggplot2")
library("nimble")
library("rstan")
library("igraph")
library("parallel")
library("mcmcplots")
library("lattice")
```

#### NIMBLE Overview

<b> Programming in NIMBLE involves a fundamental distinction between: </b> <br />
  1. the steps for an algorithm that need to happen only once, at the beginning, such as inspecting the model <br />
  2. the steps that need to happen each time a function is called, such as MCMC iterations. <br />
    When one writes a nimbleFunction, each of these parts can be provided separately. 

Multiple parameterizations for distributions, similar to those in R, can be used.
NIMBLE calls non-stochastic nodes “deterministic”, whereas BUGS calls them “logical”. 
NIMBLE uses “logical” in the way R does, to refer to boolean (TRUE/FALSE) variables.
Alternative models can be defined from the same model code by using if-then-else statements that are evaluated when the model is defined.

#### Presentation Outline
The general outline for this presentation follows along with the NIMBLE users manual <br />
http://r-nimble.org/documentation-2 <br />
However, the model(s) used here are written by us <br />

1. Build a chain binomial model in JAGS. Conduct parameter estimation <br />
2. Translate the model into NIBLE. Conduct parameter estimation <br />
      2.1 Model conversion <br />
      2.2 Compile the model <br />
      2.3 Create a basic MCMC specification for the pump model <br />
      2.4 Compile and run the MCMC <br />
3. Compare the results between these two approaches (parameter estimates, uncertainty, convergence, computation time) <br />
      3.1 Customize the MCMC specification and compile and run that <br />
4. Write the same model in STAN using a "hybrid approach" (STAN does not allow for discrete latent variables). Conduct parameter estimation and forecasting <br />
5. Translate this new model into NIMBLE. <br />
6. Compare all results <br />
7. Create, compile and run a Monte Carlo Expectation Maximization (MCEM) algorithm, which illustrates some of the flexibility NIMBLE provides to combine R and NIMBLE. <br />
8. Implement particle filtering for this same model <br />
9. Write a short nimbleFunction to generate simulations from designated nodes of any model. <br />

##### Build an SIR model in JAGS
First step is to construct the simulator from which we will obtain our data 

##### Note: It will be important to set your current working directory to "../stat744/notes/NIMBLE"

Set parameters and load the Chain Binomial simulator

```{r}
beta <- 0.02
pop <- 100
effpropS <- 0.8
effpropI <- 0.2
reporting <- 0.5
numobs <- 20

s0 <- effpropS*pop
r0 <- 0
zerohack <- 0.001
numobs <- 20
nimtimevec <- c()
source("CBsimulator.R")
```

Simulate

```{r, echo=FALSE}
sim <- simCB(beta = beta, pop = pop, effpropS = effpropS, effpropI = effpropI, 
             t0 = 1, numobs = numobs, reporting = reporting, seed = 3)
sim
```

Take a peek at what this model produces

```{r, echo=FALSE}
  ggplot(data.frame(sim), aes(time, S)) + geom_point(colour = "blue") + 
    geom_line(colour = "blue") +
    geom_line(data = data.frame(sim), aes(time, I), colour = "red") +
    geom_line(data = data.frame(sim), aes(time, R), colour = "green") +
    theme_bw()
```

Set up the required arguments to run the JAGS model

```{r}
data <- list(obs = sim$Iobs,
             pop = pop,
             numobs = nrow(sim),
             r0 = r0)

inits <- list(list(
  I = sim$I*1 + 1,
  effpropS = effpropS,
  effpropI = effpropI,
  beta = beta,
  reporting = reporting),
list(
  I = sim$I*1 + 1,
  effpropS = effpropS,
  effpropI = effpropI,
  beta = beta,
  reporting = reporting),
list(
  I = sim$I*1 + 1,
  effpropS = effpropS,
  effpropI = effpropI,
  beta = beta,
  reporting = reporting)
)

params = c("beta",
           "effpropS",
           "effpropI",
           "reporting")

#rjags::set.factory("bugs::Conjugate", FALSE, type="sampler")
```

##### Note: Many of these builds take a very long time to run. Feel free to adjust "n.iter" or "end" or load the .rda file included

Create the model and examine the MCMC algorithms that JAGS will use to sample <br />

```{r}
cbjagsmodel <- jags.model(data = data,
               inits = inits,
               file = "CB.bug",
               n.chains = length(inits))

list.samplers(cbjagsmodel)
```

Run some chains (could use coda::coda.samples from cbjagsmodel but here we will just run jags()) <br />
```{r}
jagstime <- system.time(cbjags <- jags(data = data,
               inits = inits,
               param = params,
               model.file = "CB.bug",
               n.iter = 11000,
               n.burnin = 500,
               n.thin = 20,
               n.chains = length(inits)))
```

```{r}
cbjags
xyplot(as.mcmc(cbjags))
```

Load the nimble model

```{r}
source('nimCB.R')
```

Set up the model. Here we need: Constants, Data, Initial Values, NIMBLE model object <br />

```{r}
nimCBdata <- list(obs = sim$Iobs)

nimCBcon <- list(numobs = numobs, pop = pop, r0 = r0)

nimCBinits <- list(I = sim$I,
                   effpropS = effpropS,
                   effpropI = effpropI,
                   beta = beta,
                   reporting = reporting,
                   s0 = s0)

nimtimevec[1] <- system.time(CBout <- nimbleModel(code = nimcode, 
                         name = 'CBout', 
                         constants = nimCBcon,
                         data = nimCBdata, 
                         inits = nimCBinits))[3]
```

```{r}
CBout$getNodeNames()
```

```{r}
CBout$obs
```

```{r}
par(mfrow = c(1,1))
tkplot(CBout$graph)
```

nimbleModel does its best to initialize a model, but let’s say you want to re-initialize I. <br />

```{r}
simulate(CBout, 'I')
CBout$I
```

```{r}
CBout$getDependencies(c("beta", "effpropS", "effpropI", "reporting"))
```

```{r}
CBout$getDependencies(c("beta", "effpropS", "effpropI", "reporting"), determOnly = TRUE)
```

Compile the C++ code <br />

```{r}
nimtimevec[2] <- system.time(CBoutC <- compileNimble(CBout))[3]
```

Configure the MCMC with the default options (we will return to customizing this setup later) <br />

```{r}
nimtimevec[3] <- system.time(CBoutSpec <- configureMCMC(CBout, print = TRUE))[3]
```

Add chain monitors for the parameters of interest <br />

```{r}
CBoutSpec$addMonitors(c("beta", "effpropS", "effpropI", "reporting"))
```

Build the MCMC <br />

```{r}
nimtimevec[4] <- system.time(CBoutMCMC <- buildMCMC(CBoutSpec))[3]
nimtimevec[5] <- system.time(CBoutMCMC <- compileNimble(CBoutMCMC, project = CBout, resetFunctions = TRUE))[3]
```

```{r}
niter <- 11000
set.seed(0)
nimtimevec[6] <- system.time(CBoutMCMC$run(niter))[3]
```

Quick peek at time required

```{r}
jagstime[3]
sum(nimtimevec[1:6], na.rm = TRUE)
nimtimevec[6]
```

```{r, echo = FALSE}
  samples <- as.matrix(CBoutMCMC$mvSamples)
  par(mfrow = c(1, 2), mai = c(.6, .5, .1, .2))
  plot(samples[ , 'beta'], type = 'l', xlab = 'iteration')
  plot(samples[ , 'effpropS'], type = 'l', xlab = 'iteration')
  plot(samples[ , 'effpropI'], type = 'l', xlab = 'iteration')
  plot(samples[ , 'reporting'], type = 'l', xlab = 'iteration')
  plot(samples[ , 'effpropS'], samples[ , 'effpropI'])
```

Look at the correlation in the chains

```{r}
  acf(samples[, "beta"])
  acf(samples[, "reporting"])
  acf(samples[, "effpropS"])
  acf(samples[, "effpropI"])
```

A few undesirable results here... we can add a block sampler to decrease correlation

```{r}
CBoutSpec$addSampler(target = c('effpropS', 'effpropI'), type = 'RW_block',
                      control = list(adaptInterval = 10000))
```

```{r}
CBoutSpec$setThin(25)
```

```{r}
CBoutMCMC <- buildMCMC(CBoutSpec)
```

```{r}
CBoutMCMC <- compileNimble(CBoutMCMC, project  = CBout, resetFunctions = TRUE)
```

```{r}
CBoutMCMC$run(30000)
samplesNew <- as.matrix(CBoutMCMC$mvSamples)
```

Check for an imporvement

```{r}
  par(mfrow = c(2,2))
  acf(samplesNew[, "effpropS"])
  acf(samplesNew[, "effpropI"])
  plot(samplesNew[ , 'effpropS'], type = 'l', xlab = 'iteration')
  plot(samplesNew[ , 'effpropI'], type = 'l', xlab = 'iteration')
  par(mfrow = c(1,1))
  plot(samplesNew[ , 'effpropS'], samplesNew[ , 'effpropI'])
```

##### We can also compare the NIMBLE model simultaneously with the JAGS model using MCMCsuite() <br />

Be warned: running this code will produce about 6-8 graphs which will all pop up in separate windows!

```{r}
nimcb <- MCMCsuite(code = nimcode,
                   data = nimCBdata,
                   inits = nimCBinits,
                   constants = nimCBcon,
                   MCMCs = c("jags", "nimble"),
                   monitors = c("beta", "reporting", "effpropS", "effpropI"),
                   niter = 4000,
                   makePlot = TRUE,
                   savePlot = TRUE)
```

##### To fit this model in STAN...

We must rewrite the model so that there are no discrete latent variables. We call this the "hybrid model" <br />
An asside -- Discrete Latent Variables: <br />
An additional asside -- Hamiltonian MCMC: <br />

But before we fit the model in STAN lets explore the hybrid model in NIMBLE <br />

NIMBLE allows us to compare the results of multiple models even if they have different parameterizations 
(e.g. Chain Binomial and the Hybrid Model) <br />

```{r}
data$obs <- data$obs + zerohack # Guarnantee that obs remains above 0 (important for the gamma)
data$zerohack <- zerohack

hybridjags <- jags(data = data,
               inits = inits,
               param = params,
               model.file = "hybrid.bug",
               n.iter = 8000,
               n.chains = length(inits))
```

Load ands set up the hybrid model

```{r}
source('nimhybrid.R')
```

```{r}
nimhydata <- list(obs = sim$Iobs + zerohack)
nimhycon <- list(numobs = numobs, pop = pop, r0 = r0, zerohack = zerohack)

nimhyinits <- list(I = sim$I + zerohack,
                   effpropS = effpropS,
                   effpropI = effpropI,
                   beta = beta,
                   reporting = reporting,
                   s0 = s0)
```

```{r}
nimcb <- MCMCsuite(code = nimcode,
                   data = nimhydata,
                   inits = nimhyinits,
                   constants = nimhycon,
                   MCMCs = c("jags", "nimble"),
                   monitors = c("beta", "reporting", "effpropS", "effpropI"),
                   niter = 4000,
                   makePlot = TRUE,
                   savePlot = TRUE)
```

Set up the stan model

```{r}
s1 <- stan(file='hybrid.stan', data = data, init = inits,
           pars=c("beta", "reporting", "effpropS", "effpropI", "I"), iter = 8000,
           seed = 1001,
           chains = 1)
```



#### Everything below this old stuff



```{r}
simNodesMany <- nimbleFunction(
  setup = function(model, nodes) {
  mv <- modelValues(model)
  deps <- model$getDependencies(nodes)
  allNodes <- model$getNodeNames()
  },
  run = function(n = integer()) {
    resize(mv, n)
      for(i in 1:n) {
        simulate(model, nodes)
        calculate(model, deps)
        copy(from = model, nodes = allNodes,
        to = mv, rowTo = i, logProb = TRUE)
      }
  })
```

```{r}
simNodesTheta1to5 <- simNodesMany(pump, 'theta[1:5]')
simNodesTheta6to10 <- simNodesMany(pump, 'theta[6:10]')
```

```{r}
set.seed(0)
pump$alpha <- pumpMLE[1]
pump$beta <- pumpMLE[2]
```

```{r}
calculate(pump, pump$getDependencies(c('alpha','beta'), determOnly = TRUE))
```

```{r}
saveTheta <- pump$theta
simNodesTheta1to5$run(10)
simNodesTheta1to5$mv[['theta']][1:2]
```

```{r}
simNodesTheta1to5$mv[['logProb_x']][1:2]
```

### The NIMBLE algorithm library

1. MCMC with samplers including conjugate, slice, adaptive random walk, and adaptive
block random walk. NIMBLE’s MCMC system illustrates the flexibility of combining R
and C++. An R function inspects the model object and creates an MCMC specification
object representing choices of which kind of sampler to use for each node. <br />
2. A nimbleFunction that provides a likelihood function for arbitrary sets of nodes in
any model. This can be useful for simple maximum likelihood estimation of nonhierarchical
models using R’s optimization functions. And it can be useful for other R
packages that run algorithms on any likelihood function. <br />
3. A nimbleFunction that provides ability to simulate, calculate, or retrieve the summed
log probability (density) of many sets of values for arbitrary sets of nodes.
4. A nimbleFunction that provides a basic particle filter for a state-space model. <br />
5. A basic Monte Carlo Expectation Maximization (MCEM) algorithm. MCEM has its <br />
issues as an algorithm, such as potentially slow convergence to the maximum likelihood
(i.e., empirical Bayes in this context) estimates, but we chose it as a good illustration
of how NIMBLE can be used. Each MCMC step uses NIMBLE’s MCMC; the objective
function for maximization is another nimbleFunction; and the actual maximization
is done through R’s optim function1 <br />



```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

Can also do EM

```{r}
pump2 <- pump$newModel()
```

```{r}
box = list( list(c('alpha','beta'), c(0, Inf)))
```

```{r}
pumpMCEM <- buildMCEM(model = pump2, latentNodes = 'theta[1:10]',
boxConstraints = box)
```

```{r}
pumpMLE <- pumpMCEM()
```

```{r}
pumpMLE
```






