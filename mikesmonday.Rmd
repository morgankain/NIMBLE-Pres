---
title: "Monday NIMBLE"
author: "Mike Li, Morgan Kain"
date:  "`r format(Sys.time(), '%H:%M %d %B %Y')`"
output: html_document
---

```{r setup}
library(knitr)
options(mc.cores = parallel::detectCores())
#opts_chunk$set(cache = TRUE)
```

## NIMBLE: Numerical Inference for statistical Models for Bayesian and Likelihood Estimation

NIMBLE is built in R but compiles your models and algorithms using C++ for speed <br />
NIMBLE is most commonly used for MCMC but can also be used to implement a series of other algorithms (e.g. particle filtering, MCEM) <br />
<br />
1. A system for writing statistical models flexibly, which is an extension of the BUGS language <br />
2. A library of algorithms such as MCMC. <br />
3. A language, called NIMBLE, embedded within and similar in style to R, for writing algorithms that operate on BUGS models. <br />
  
One of the most important concepts behind NIMBLE is to allow a combination of highlevel processing in R and low-level processing in compiled C++. <br />
<br />

##### Why NIMBLE?

1. Options (More customizable MCMC, ability to run JAGS models and STAN models, EM, particle filter) that leads to a more adaptable workflow <br />
2. User-defined functions and distributions – written as nimbleFunctions – can be used in model code.  <br />
3. Multiple parameterizations for distributions, similar to those in R, can be used. <br />
<br />
  e.g. normal distribution with BUGS parameter order: <br />
        x ~ dnorm(a + b * c, tau) <br />
       normal distribution with a named parameter: <br />
        y ~ dnorm(a + b * c, sd = sigma) <br />
<br />
4. Named parameters for distributions and functions, similar to R function calls, can be used. <br />
5. More flexible indexing of vector nodes within larger variables is allowed. For example one can place a multivariate normal vector arbitrarily within a higher-dimensional object, not just in the last index. <br />
6. More general constraints can be declared using dconstraint, which extends the concept of JAGS’ dinterval. <br />
<br />

#### Downloading, installing and loading NIMBLE

On Windows, you should download and install Rtools.exe available from http://cran. r-project.org/bin/windows/Rtools/.  <br />
On OS X, you should install Xcode.  <br />

After these are installed you can install NIMBLE in R using <br />
install.packages("nimble", repos = "http://r-nimble.org", type = "source") <br />

Please post about installation problems to the nimble-users Google group or email nimble.stats@gmail.com.

You will also need to download STAN using the following commands <br />
Sys.setenv(MAKEFLAGS = "-j4") <br />
install.packages("rstan", dependencies = TRUE) <br />
<br />

In total you will need the following pakages:

```{r loadpackage, echo=TRUE, message=FALSE, verbose = FALSE}
library("nimble")
library("R2jags")
library("ggplot2")
library("igraph")
library("parallel")
library("mcmcplots")
library("lattice")
library("coda")
library("reshape2")
```

<br />
<br />

#### Things to know about working with NIMBLE

<b> Programming in NIMBLE involves a fundamental distinction between: </b> <br />
  1. the steps for an algorithm that need to happen only once, at the beginning, such as inspecting the model <br />
  2. the steps that need to happen each time a function is called, such as MCMC iterations. <br />
  <br />
    When one writes a nimbleFunction, each of these parts can be provided separately. 
<br />

Multiple parameterizations for distributions, similar to those in R, can be used.
NIMBLE calls non-stochastic nodes “deterministic”, whereas BUGS calls them “logical”. 
NIMBLE uses “logical” in the way R does, to refer to boolean (TRUE/FALSE) variables. <br />
Alternative models can be defined from the same model code by using if-then-else statements that are evaluated when the model is defined.

1. NIMBLE extracts all the declarations in the BUGS code to create a model definition. <br />
2. From the model definition, NIMBLE builds a working model in R. This can be used to manipulate variables and operate the model from R. Operating the model includes calculating, simulating, or querying the log probability value of model nodes. <br />
3. From the working model, NIMBLE generates customized C++ code representing the model, compiles the C++, loads it back into R, and provides an R object that interfaces to it. We often call the uncompiled model the “R-model” and the compiled model the “C-model.” <br />  
<br />

### Presentation Outline
The general outline for this presentation follows along with the NIMBLE users manual <br />
http://r-nimble.org/documentation-2 <br />
However, the model(s) used here are written by us <br />

##### Part 1
[1.1](#1.1) Build a chain binomial model in JAGS. Conduct parameter estimation <br />
[1.2](#1.2) Translate the model into NIBLE. Conduct parameter estimation <br />
\ \ \ \ \ [1.2.1](#1.2.1) Model exploration/conversion <br />
\ \ \ \ \ [1.2.2](#1.2.2) Create a basic MCMC specification for the chain binomial, compile and run the MCMC <br />
\ \ \ \ \ [1.2.3](#1.2.3) Small MCMC specification adjustments (more on this in Part 3) <br />
[1.3](#1.3) Compare the JAGS and NIMBLE results (parameter estimates, uncertainty, convergence, efficiency) <br />

##### Part 2
[2.1](#2.1) Translate the model using a "hybrid approach" (STAN does not allow for discrete latent variables) <br />
\ \ \ \ \ [2.1.1](#1.4.1) Conduct parameter estimation using JAGS and NIMBLE <br />
\ \ \ \ \ [2.1.2](#1.4.2) Run the hybrid model in STAN and compare the results from JAGS, NIMBLE and STAN <br />
[2.2](#2.2) Compare the NIMBLE Chain Binomial and STAN hybrid model <br />

##### Part 3
[3.1](#3.1) Expolore more fine-tuned adjustments that can be made in NIMBLE <br />
\ \ \ \ \ [3.1.1](#3.1.1)  NIMBLE functions (e.g. allows for the implementation of custom samplers) <br />
      
##### Part 4     
[4.1](#4.1) NIMBLE extras: <br />
\ \ \ \ \ [4.1.1](#4.1.1) Create, compile and run a Monte Carlo Expectation Maximization (MCEM) algorithm, which illustrates some of the flexibility NIMBLE provides to combine R and NIMBLE. <br />
\ \ \ \ \ [4.1.2](#4.1.2) Implement particle filtering for the chain binomial <br />
      
##### Part 5

[5.1](#5.1) Misc NIMBLE notes (truncated distributions, lifted nodes, logProb, multiple instances of the same model)

<br />

### Part 1

##### <a name="1.1"> 1.1 Build a chain binomial model in JAGS </a>
First step is to construct the simulator from which we will obtain our data <br />

Note: It will be important to set your current working directory to "../stat744/notes/NIMBLE" <br />

Set parameters and load the Chain Binomial simulator <br />

```{r, "Homework"}
source("simulateCB.R")
options(mc.cores = parallel::detectCores())
source('nimCB.R')

nimCBdata <- list(obs=sim$Iobs)
nimCBcon <- list(numobs=numobs,N=N,i0=i0)

nimCBinits <- list(I=sim$I,
                   effprop=effprop,
                   beta=beta,
                   reporting=reporting,
                   N0=N0
)
NimbleCB <- MCMCsuite(code=nimcode,
                   data=nimCBdata,
                   inits=nimCBinits,
                   constants=nimCBcon,
                   MCMCs=c("jags","nimble"),
                   monitors=c("beta","reporting","effprop"),
                   calculateEfficiency=TRUE,
                   niter=iterations,
                   makePlot=FALSE,
                   savePlot=FALSE,
                   setSeed = 5)

print(NimbleCB$timing)
print(NimbleCB$summary)

```

It is kind of scary considering Nimble is suppose to be this awesome super fast magic box. Before we learn Nimble, let's take a few minutes learning JAGS and samplers.


```{r, Jags Example}

rjags::set.factory("bugs::Conjugate", FALSE, type="sampler")

Jagsmod <- jags.model(file="CB2.bug",data=data,inits=inits)

list.samplers(Jagsmod)

slicetime <- system.time(JagsCB <- jags(data=data,
               inits=inits,
               param = params,
               model.file = "CB2.bug",
               n.iter = iterations,
               n.chains = length(inits),
               n.thin = 1,
               n.burnin = 2000
               ))

print(JagsCB)
slice_eff <- effectiveSize(as.mcmc(JagsCB))/slicetime[3]


rjags::set.factory("bugs::Conjugate", TRUE, type="sampler")

Jagsmod2 <- jags.model(file="CB2.bug",data=data,inits=inits)

list.samplers(Jagsmod2)

conjutime <- system.time(JagsCB2 <- jags(data=data,
               inits=inits,
               param = params,
               model.file = "CB2.bug",
               n.iter = iterations,
               n.chains = length(inits),
               n.thin = 1,
               n.burnin = 2000
               ))
print(JagsCB)
print(JagsCB2)
conju_eff <- effectiveSize(as.mcmc(JagsCB2))/conjutime[3]

slicetime
conjutime

slice_eff
conju_eff
```

Wow, that is pretty cool. Let's try to do it in Nimble. 

```{r, NimbleCB}
NimbleCB <- MCMCsuite(code=nimcode,
                   data=nimCBdata,
                   inits=nimCBinits,
                   constants=nimCBcon,
                   MCMCs=c("jags","nimble","nimble_slice"),
                   monitors=c("beta","reporting","effprop"),
                   calculateEfficiency=TRUE,
                   niter=iterations,
                   makePlot=FALSE,
                   savePlot=FALSE,
                   setSeed = 5)

print(NimbleCB$timing)
print(NimbleCB$summary)

```

Why is default Nimble underperforming? (vs Jags) Take my word, nimble-jags is NOT using conjugate samplers. Nimble slice turns all nodes to slice samplers, thus, nimble-jags and nimble slice is using the same sampler. As you can see Nimble slice is more efficient than JAGS.

```{r, "Investigating default Nimble"}
mod <- nimbleModel(code = nimcode, data=nimCBdata, inits=nimCBinits, constants=nimCBcon, name = "mod")
temp <- compileNimble(mod) ## need to compile it once before recompiling changes
Cmod <- configureMCMC(mod,print=TRUE,useConjugacy = TRUE)
Cmodslice <- configureMCMC(mod,print=TRUE,useConjugacy = TRUE, onlySlice = TRUE)
Cmod$removeSamplers(c("reporting","beta","effprop"))
Cmod$addSampler(target = c("reporting","effprop"), type="RW_block")
Cmod$addSampler("beta",type="slice")
Cmod$addMonitors(c("reporting","beta","effprop"))

newMCMC <- buildMCMC(Cmod)
CnewMCMC <- compileNimble(newMCMC,project = mod, resetFunctions = TRUE)

Cnewtime <- system.time(CnewMCMC$run(iterations))
Cnewsample <- as.matrix(CnewMCMC$mvSamples)
effectiveSize(as.mcmc(Cnewsample[,c('beta','effprop','reporting')]))/Cnewtime[3]

```

```{r, "combine everything"}
NimbleCB <- MCMCsuite(code=nimcode,
                   data=nimCBdata,
                   inits=nimCBinits,
                   constants=nimCBcon,
                   MCMCs=c("jags","nimble","nimble_slice","newMCMC"),
                   monitors=c("beta","reporting","effprop"),
                   MCMCdefs = list(
                     newMCMC = quote({
                     Cmod <- configureMCMC(mod,print=FALSE,useConjugacy = TRUE)
                     Cmod$removeSamplers(c("reporting","beta","effprop"))
                     Cmod$addSampler(target = c("reporting","effprop"), type="RW_block")
                     Cmod$addSampler("beta",type="slice")
                     Cmod
                   })),
                   calculateEfficiency=TRUE,
                   niter=iterations,
                   makePlot=FALSE,
                   savePlot=FALSE,
                   setSeed = 5)

print(NimbleCB$timing)
print(NimbleCB$summary)

```

```{r, "conjugates"}
source("nimCB2.R")
mod2 <- nimbleModel(code = nimcode, data=nimCBdata, inits=nimCBinits, constants = nimCBcon,
                    name= "mod2")
Cmod2 <- configureMCMC(mod2,print=TRUE)

NimbleCB2 <- MCMCsuite(code=nimcode,
                   data=nimCBdata,
                   inits=nimCBinits,
                   constants=nimCBcon,
                   MCMCs=c("jags","nimble","nimble_slice"),
                   monitors=c("beta","reporting","effprop"),
                   calculateEfficiency=TRUE,
                   niter=iterations,
                   makePlot=FALSE,
                   savePlot=FALSE,
                   setSeed = 5)
print(NimbleCB$timing)
print(NimbleCB2$timing)
print(NimbleCB2$summary)

mat1 <- as.array(NimbleCB$summary)
mat2 <- as.array(NimbleCB2$summary)
mat1 <- mat1[,"efficiency",]
mat2 <- mat2[,"efficiency",]
a1 <- melt(mat1)
a2 <- melt(mat2)
a1 <- cbind(a1,var3="NoConjugates")
a2 <- cbind(a2,var3="YesConjugates")
dat <- rbind(a1,a2)

ggplot(dat,aes(x=var3, y=log10(value),group=interaction(Var1,Var2))) + geom_line(aes(color=interaction(Var1),linetype=Var2)) + geom_point(aes(color=Var1)) + theme_bw() + ylab('Efficiency (log10)') + xlab("speed hack")



```


